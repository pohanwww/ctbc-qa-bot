# CTBC QA Bot Configuration
# Copy this file to .env and fill in the values

# =============================================================================
# Model Configuration
# =============================================================================

# Hugging Face model ID for the base LLM
# Default: Qwen/Qwen3-4B
HF_MODEL_ID=Qwen/Qwen3-4B

# Hugging Face model ID for embeddings
# Default: BAAI/bge-m3 (multilingual, supports Chinese)
HF_EMBEDDING_MODEL_ID=BAAI/bge-m3

# Path to LoRA adapter (optional, leave empty to use base model)
LORA_ADAPTER_PATH=

# Hugging Face API token (optional, for gated models)
HF_TOKEN=

# =============================================================================
# RAG Configuration
# =============================================================================

# Path to FAISS index directory
FAISS_INDEX_PATH=artifacts/faiss

# Number of documents to retrieve
RAG_TOP_K=3

# =============================================================================
# Inference Configuration
# =============================================================================

# Maximum new tokens to generate
MAX_NEW_TOKENS=512

# Temperature for generation (0.0 = deterministic, 1.0 = creative)
TEMPERATURE=0.7

# Device to use (auto, cuda, cpu, mps)
DEVICE=auto

# =============================================================================
# Data Paths
# =============================================================================

# Path to processed CTBC FAQ data
CTBC_FAQ_PATH=data/processed/ctbc_faq

# Path to fine-tuning data
FINETUNE_DATA_PATH=data/processed/finetune

# =============================================================================
# Training Configuration (for fine-tuning)
# =============================================================================

# Weights & Biases project name (optional)
WANDB_PROJECT=ctbc-qa-bot

# Output directory for trained models
OUTPUT_DIR=artifacts/models
